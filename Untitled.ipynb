{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aef4d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/megvii/anaconda3/envs/paul-py3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from utilities import comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RepeatFactorTrainingSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Similar to TrainingSampler, but suitable for training on class imbalanced datasets\n",
    "    like LVIS. In each epoch, an image may appear multiple times based on its \"repeat\n",
    "    factor\". The repeat factor for an image is a function of the frequency the rarest\n",
    "    category labeled in that image. The \"frequency of category c\" in [0, 1] is defined\n",
    "    as the fraction of images in the training set (without repeats) in which category c\n",
    "    appears.\n",
    "\n",
    "    See https://arxiv.org/abs/1908.03195 (>= v2) Appendix B.2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_dicts, repeat_thresh, shuffle=True, seed=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_dicts (list[dict]): annotations in Detectron2 dataset format.\n",
    "            repeat_thresh (float): frequency threshold below which data is repeated.\n",
    "            shuffle (bool): whether to shuffle the indices or not\n",
    "            seed (int): the initial seed of the shuffle. Must be the same\n",
    "                across all workers. If None, will use a random seed shared\n",
    "                among workers (require synchronization among all workers).\n",
    "        \"\"\"\n",
    "        self._shuffle = shuffle\n",
    "        if seed is None:\n",
    "            seed = comm.shared_random_seed()\n",
    "        self._seed = int(seed)\n",
    "\n",
    "        self._rank = comm.get_rank()\n",
    "        self._world_size = comm.get_world_size()\n",
    "\n",
    "        # Get fractional repeat factors and split into whole number (_int_part)\n",
    "        # and fractional (_frac_part) parts.\n",
    "        rep_factors = self._get_repeat_factors(dataset_dicts, repeat_thresh)\n",
    "        self._int_part = torch.trunc(rep_factors)\n",
    "        self._frac_part = rep_factors - self._int_part\n",
    "\n",
    "    def _get_repeat_factors(self, dataset_dicts, repeat_thresh):\n",
    "        \"\"\"\n",
    "        Compute (fractional) per-image repeat factors.\n",
    "\n",
    "        Args:\n",
    "            See __init__.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: the i-th element is the repeat factor for the dataset image\n",
    "                at index i.\n",
    "        \"\"\"\n",
    "        # 1. For each category c, compute the fraction of images that contain it: f(c)\n",
    "        category_freq = defaultdict(int)\n",
    "        for dataset_dict in dataset_dicts:  # For each image (without repeats)\n",
    "            cat_ids = {ann[\"category_id\"] for ann in dataset_dict[\"annotations\"]}\n",
    "            for cat_id in cat_ids:\n",
    "                category_freq[cat_id] += 1\n",
    "        num_images = len(dataset_dicts)\n",
    "        for k, v in category_freq.items():\n",
    "            category_freq[k] = v / num_images\n",
    "\n",
    "        # 2. For each category c, compute the category-level repeat factor:\n",
    "        #    r(c) = max(1, sqrt(t / f(c)))\n",
    "        category_rep = {\n",
    "            cat_id: max(1.0, math.sqrt(repeat_thresh / cat_freq))\n",
    "            for cat_id, cat_freq in category_freq.items()\n",
    "        }\n",
    "\n",
    "        # 3. For each image I, compute the image-level repeat factor:\n",
    "        #    r(I) = max_{c in I} r(c)\n",
    "        rep_factors = []\n",
    "        for dataset_dict in dataset_dicts:\n",
    "            cat_ids = {ann[\"category_id\"] for ann in dataset_dict[\"annotations\"]}\n",
    "            rep_factor = max({category_rep[cat_id] for cat_id in cat_ids})\n",
    "            rep_factors.append(rep_factor)\n",
    "\n",
    "        return torch.tensor(rep_factors, dtype=torch.float32)\n",
    "\n",
    "    def _get_epoch_indices(self, generator):\n",
    "        \"\"\"\n",
    "        Create a list of dataset indices (with repeats) to use for one epoch.\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): pseudo random number generator used for\n",
    "                stochastic rounding.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: list of dataset indices to use in one epoch. Each index\n",
    "                is repeated based on its calculated repeat factor.\n",
    "        \"\"\"\n",
    "        # Since repeat factors are fractional, we use stochastic rounding so\n",
    "        # that the target repeat factor is achieved in expectation over the\n",
    "        # course of training\n",
    "        rands = torch.rand(len(self._frac_part), generator=generator)\n",
    "        rep_factors = self._int_part + (rands < self._frac_part).float()\n",
    "        # Construct a list of indices in which we repeat images as specified\n",
    "        indices = []\n",
    "        for dataset_index, rep_factor in enumerate(rep_factors):\n",
    "            indices.extend([dataset_index] * int(rep_factor.item()))\n",
    "        return torch.tensor(indices, dtype=torch.int64)\n",
    "\n",
    "    def __iter__(self):\n",
    "        start = self._rank\n",
    "        yield from itertools.islice(self._infinite_indices(), start, None, self._world_size)\n",
    "\n",
    "    def _infinite_indices(self):\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(self._seed)\n",
    "        while True:\n",
    "            # Sample indices with repeats determined by stochastic rounding; each\n",
    "            # \"epoch\" may have a slightly different size due to the rounding.\n",
    "            indices = self._get_epoch_indices(g)\n",
    "            if self._shuffle:\n",
    "                randperm = torch.randperm(len(indices), generator=g)\n",
    "                yield from indices[randperm]\n",
    "            else:\n",
    "                yield from indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda1b198",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_pri\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PriDataset, PriDatasetExt\n\u001b[0;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m PriDataset(\u001b[43margs\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/tmp_data/hard01/train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from dataset.dataset_pri import PriDataset, PriDatasetExt\n",
    "\n",
    "train_dataset = PriDataset(args, 'data/tmp_data/hard01/train', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc684977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39e033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
