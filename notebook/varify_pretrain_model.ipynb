{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93406355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/megvii/anaconda3/envs/paul-py3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5911932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_esm2_cp = \"../dataset/checkpoints/pmnet/pre_train.2.99000.ckpt\"\n",
    "checkpoint = torch.load(path_esm2_cp, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a38448",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom_level_sub_graph.layer_0.linear.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layer_0.linear.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layer_0.layer_norm.weight     torch.Size([128])\n",
      "atom_level_sub_graph.layer_0.layer_norm.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.0.query.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.0.query.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.0.key.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.0.key.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.0.value.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.0.value.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.1.query.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.1.query.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.1.key.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.1.key.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.1.value.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.1.value.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.2.query.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.2.query.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.2.key.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.2.key.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers.2.value.weight     torch.Size([128, 128])\n",
      "atom_level_sub_graph.layers.2.value.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers_2.0.weight     torch.Size([128])\n",
      "atom_level_sub_graph.layers_2.0.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers_2.1.weight     torch.Size([128])\n",
      "atom_level_sub_graph.layers_2.1.bias     torch.Size([128])\n",
      "atom_level_sub_graph.layers_2.2.weight     torch.Size([128])\n",
      "atom_level_sub_graph.layers_2.2.bias     torch.Size([128])\n",
      "laneGCN_A2L.query.weight     torch.Size([128, 128])\n",
      "laneGCN_A2L.query.bias     torch.Size([128])\n",
      "laneGCN_A2L.key.weight     torch.Size([128, 128])\n",
      "laneGCN_A2L.key.bias     torch.Size([128])\n",
      "laneGCN_A2L.value.weight     torch.Size([128, 128])\n",
      "laneGCN_A2L.value.bias     torch.Size([128])\n",
      "laneGCN_L2L.global_graph.query.weight     torch.Size([64, 128])\n",
      "laneGCN_L2L.global_graph.query.bias     torch.Size([64])\n",
      "laneGCN_L2L.global_graph.key.weight     torch.Size([64, 128])\n",
      "laneGCN_L2L.global_graph.key.bias     torch.Size([64])\n",
      "laneGCN_L2L.global_graph.value.weight     torch.Size([64, 128])\n",
      "laneGCN_L2L.global_graph.value.bias     torch.Size([64])\n",
      "laneGCN_L2L.global_graph2.query.weight     torch.Size([64, 128])\n",
      "laneGCN_L2L.global_graph2.query.bias     torch.Size([64])\n",
      "laneGCN_L2L.global_graph2.key.weight     torch.Size([64, 128])\n",
      "laneGCN_L2L.global_graph2.key.bias     torch.Size([64])\n",
      "laneGCN_L2L.global_graph2.value.weight     torch.Size([64, 128])\n",
      "laneGCN_L2L.global_graph2.value.bias     torch.Size([64])\n",
      "laneGCN_L2A.query.weight     torch.Size([128, 128])\n",
      "laneGCN_L2A.query.bias     torch.Size([128])\n",
      "laneGCN_L2A.key.weight     torch.Size([128, 128])\n",
      "laneGCN_L2A.key.bias     torch.Size([128])\n",
      "laneGCN_L2A.value.weight     torch.Size([128, 128])\n",
      "laneGCN_L2A.value.bias     torch.Size([128])\n",
      "laneGCN_A2A.global_graph.query.weight     torch.Size([64, 128])\n",
      "laneGCN_A2A.global_graph.query.bias     torch.Size([64])\n",
      "laneGCN_A2A.global_graph.key.weight     torch.Size([64, 128])\n",
      "laneGCN_A2A.global_graph.key.bias     torch.Size([64])\n",
      "laneGCN_A2A.global_graph.value.weight     torch.Size([64, 128])\n",
      "laneGCN_A2A.global_graph.value.bias     torch.Size([64])\n",
      "laneGCN_A2A.global_graph2.query.weight     torch.Size([64, 128])\n",
      "laneGCN_A2A.global_graph2.query.bias     torch.Size([64])\n",
      "laneGCN_A2A.global_graph2.key.weight     torch.Size([64, 128])\n",
      "laneGCN_A2A.global_graph2.key.bias     torch.Size([64])\n",
      "laneGCN_A2A.global_graph2.value.weight     torch.Size([64, 128])\n",
      "laneGCN_A2A.global_graph2.value.bias     torch.Size([64])\n",
      "global_graph.global_graph.query.weight     torch.Size([64, 128])\n",
      "global_graph.global_graph.query.bias     torch.Size([64])\n",
      "global_graph.global_graph.key.weight     torch.Size([64, 128])\n",
      "global_graph.global_graph.key.bias     torch.Size([64])\n",
      "global_graph.global_graph.value.weight     torch.Size([64, 128])\n",
      "global_graph.global_graph.value.bias     torch.Size([64])\n",
      "global_graph.global_graph2.query.weight     torch.Size([64, 128])\n",
      "global_graph.global_graph2.query.bias     torch.Size([64])\n",
      "global_graph.global_graph2.key.weight     torch.Size([64, 128])\n",
      "global_graph.global_graph2.key.bias     torch.Size([64])\n",
      "global_graph.global_graph2.value.weight     torch.Size([64, 128])\n",
      "global_graph.global_graph2.value.bias     torch.Size([64])\n",
      "aa_seq_layer.module.weight     torch.Size([64, 20])\n",
      "aa_pos_emb.weights_0     torch.Size([1, 94, 1, 64])\n",
      "aa_pos_emb.weights_1     torch.Size([1, 1, 64, 64])\n",
      "na_seq_norm.weight     torch.Size([64])\n",
      "na_seq_norm.bias     torch.Size([64])\n",
      "prot_chm_layer.module.weight     torch.Size([64, 7])\n",
      "aa_chm_pos_emb.weights_0     torch.Size([1, 94, 1, 64])\n",
      "aa_chm_pos_emb.weights_1     torch.Size([1, 1, 64, 64])\n",
      "na_chm_norm.weight     torch.Size([64])\n",
      "na_chm_norm.bias     torch.Size([64])\n",
      "na_conv2d.conv.weight     torch.Size([8, 1, 3, 5])\n",
      "na_conv2d.conv.bias     torch.Size([8])\n",
      "na_conv2d.bn.weight     torch.Size([8])\n",
      "na_conv2d.bn.bias     torch.Size([8])\n",
      "na_conv2d.bn.running_mean     torch.Size([8])\n",
      "na_conv2d.bn.running_var     torch.Size([8])\n",
      "na_conv2d.bn.num_batches_tracked     torch.Size([])\n",
      "na_fc.weight     torch.Size([128, 32])\n",
      "na_norm.weight     torch.Size([128])\n",
      "na_norm.bias     torch.Size([128])\n",
      "na_pos_emb.weights_0     torch.Size([1, 16, 1, 128])\n",
      "na_pos_emb.weights_1     torch.Size([1, 1, 64, 128])\n",
      "reg_head.weight     torch.Size([128, 256])\n",
      "reg_pred.weight     torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "for k, v in checkpoint['state_dict'].items():\n",
    "    print(k, \"   \", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef959460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_esm2_cp = \"../dataset/checkpoints/pretrain_esm_dbert_layer5_mse.ckpt\"\n",
    "\n",
    "path_esm2_cp = \"../dataset/checkpoints/tmp_1017.ckpt\"\n",
    "checkpoint = torch.load(path_esm2_cp, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fea1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esm2.embed_tokens.weight     torch.Size([33, 320])\n",
      "esm2.layers.0.self_attn.k_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.0.self_attn.k_proj.bias     torch.Size([320])\n",
      "esm2.layers.0.self_attn.v_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.0.self_attn.v_proj.bias     torch.Size([320])\n",
      "esm2.layers.0.self_attn.q_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.0.self_attn.q_proj.bias     torch.Size([320])\n",
      "esm2.layers.0.self_attn.out_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.0.self_attn.out_proj.bias     torch.Size([320])\n",
      "esm2.layers.0.self_attn.rot_emb.inv_freq     torch.Size([8])\n",
      "esm2.layers.0.self_attn_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.0.self_attn_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.0.fc1.weight     torch.Size([1280, 320])\n",
      "esm2.layers.0.fc1.bias     torch.Size([1280])\n",
      "esm2.layers.0.fc2.weight     torch.Size([320, 1280])\n",
      "esm2.layers.0.fc2.bias     torch.Size([320])\n",
      "esm2.layers.0.final_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.0.final_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.1.self_attn.k_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.1.self_attn.k_proj.bias     torch.Size([320])\n",
      "esm2.layers.1.self_attn.v_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.1.self_attn.v_proj.bias     torch.Size([320])\n",
      "esm2.layers.1.self_attn.q_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.1.self_attn.q_proj.bias     torch.Size([320])\n",
      "esm2.layers.1.self_attn.out_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.1.self_attn.out_proj.bias     torch.Size([320])\n",
      "esm2.layers.1.self_attn.rot_emb.inv_freq     torch.Size([8])\n",
      "esm2.layers.1.self_attn_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.1.self_attn_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.1.fc1.weight     torch.Size([1280, 320])\n",
      "esm2.layers.1.fc1.bias     torch.Size([1280])\n",
      "esm2.layers.1.fc2.weight     torch.Size([320, 1280])\n",
      "esm2.layers.1.fc2.bias     torch.Size([320])\n",
      "esm2.layers.1.final_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.1.final_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.2.self_attn.k_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.2.self_attn.k_proj.bias     torch.Size([320])\n",
      "esm2.layers.2.self_attn.v_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.2.self_attn.v_proj.bias     torch.Size([320])\n",
      "esm2.layers.2.self_attn.q_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.2.self_attn.q_proj.bias     torch.Size([320])\n",
      "esm2.layers.2.self_attn.out_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.2.self_attn.out_proj.bias     torch.Size([320])\n",
      "esm2.layers.2.self_attn.rot_emb.inv_freq     torch.Size([8])\n",
      "esm2.layers.2.self_attn_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.2.self_attn_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.2.fc1.weight     torch.Size([1280, 320])\n",
      "esm2.layers.2.fc1.bias     torch.Size([1280])\n",
      "esm2.layers.2.fc2.weight     torch.Size([320, 1280])\n",
      "esm2.layers.2.fc2.bias     torch.Size([320])\n",
      "esm2.layers.2.final_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.2.final_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.3.self_attn.k_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.3.self_attn.k_proj.bias     torch.Size([320])\n",
      "esm2.layers.3.self_attn.v_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.3.self_attn.v_proj.bias     torch.Size([320])\n",
      "esm2.layers.3.self_attn.q_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.3.self_attn.q_proj.bias     torch.Size([320])\n",
      "esm2.layers.3.self_attn.out_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.3.self_attn.out_proj.bias     torch.Size([320])\n",
      "esm2.layers.3.self_attn.rot_emb.inv_freq     torch.Size([8])\n",
      "esm2.layers.3.self_attn_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.3.self_attn_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.3.fc1.weight     torch.Size([1280, 320])\n",
      "esm2.layers.3.fc1.bias     torch.Size([1280])\n",
      "esm2.layers.3.fc2.weight     torch.Size([320, 1280])\n",
      "esm2.layers.3.fc2.bias     torch.Size([320])\n",
      "esm2.layers.3.final_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.3.final_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.4.self_attn.k_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.4.self_attn.k_proj.bias     torch.Size([320])\n",
      "esm2.layers.4.self_attn.v_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.4.self_attn.v_proj.bias     torch.Size([320])\n",
      "esm2.layers.4.self_attn.q_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.4.self_attn.q_proj.bias     torch.Size([320])\n",
      "esm2.layers.4.self_attn.out_proj.weight     torch.Size([320, 320])\n",
      "esm2.layers.4.self_attn.out_proj.bias     torch.Size([320])\n",
      "esm2.layers.4.self_attn.rot_emb.inv_freq     torch.Size([8])\n",
      "esm2.layers.4.self_attn_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.4.self_attn_layer_norm.bias     torch.Size([320])\n",
      "esm2.layers.4.fc1.weight     torch.Size([1280, 320])\n",
      "esm2.layers.4.fc1.bias     torch.Size([1280])\n",
      "esm2.layers.4.fc2.weight     torch.Size([320, 1280])\n",
      "esm2.layers.4.fc2.bias     torch.Size([320])\n",
      "esm2.layers.4.final_layer_norm.weight     torch.Size([320])\n",
      "esm2.layers.4.final_layer_norm.bias     torch.Size([320])\n",
      "esm2.emb_layer_norm_after.weight     torch.Size([320])\n",
      "esm2.emb_layer_norm_after.bias     torch.Size([320])\n",
      "dbm.embeddings.word_embeddings.weight     torch.Size([1029, 768])\n",
      "dbm.embeddings.position_embeddings.weight     torch.Size([512, 768])\n",
      "dbm.embeddings.token_type_embeddings.weight     torch.Size([2, 768])\n",
      "dbm.embeddings.LayerNorm.weight     torch.Size([768])\n",
      "dbm.embeddings.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.attention.self.query.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.0.attention.self.query.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.attention.self.key.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.0.attention.self.key.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.attention.self.value.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.0.attention.self.value.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.attention.output.dense.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.0.attention.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.attention.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.0.attention.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.intermediate.dense.weight     torch.Size([3072, 768])\n",
      "dbm.encoder.layer.0.intermediate.dense.bias     torch.Size([3072])\n",
      "dbm.encoder.layer.0.output.dense.weight     torch.Size([768, 3072])\n",
      "dbm.encoder.layer.0.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.0.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.0.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.attention.self.query.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.1.attention.self.query.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.attention.self.key.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.1.attention.self.key.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.attention.self.value.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.1.attention.self.value.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.attention.output.dense.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.1.attention.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.attention.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.1.attention.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.intermediate.dense.weight     torch.Size([3072, 768])\n",
      "dbm.encoder.layer.1.intermediate.dense.bias     torch.Size([3072])\n",
      "dbm.encoder.layer.1.output.dense.weight     torch.Size([768, 3072])\n",
      "dbm.encoder.layer.1.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.1.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.1.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.attention.self.query.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.2.attention.self.query.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.attention.self.key.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.2.attention.self.key.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.attention.self.value.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.2.attention.self.value.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.attention.output.dense.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.2.attention.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.attention.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.2.attention.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.intermediate.dense.weight     torch.Size([3072, 768])\n",
      "dbm.encoder.layer.2.intermediate.dense.bias     torch.Size([3072])\n",
      "dbm.encoder.layer.2.output.dense.weight     torch.Size([768, 3072])\n",
      "dbm.encoder.layer.2.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.2.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.2.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.attention.self.query.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.3.attention.self.query.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.attention.self.key.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.3.attention.self.key.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.attention.self.value.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.3.attention.self.value.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.attention.output.dense.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.3.attention.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.attention.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.3.attention.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.intermediate.dense.weight     torch.Size([3072, 768])\n",
      "dbm.encoder.layer.3.intermediate.dense.bias     torch.Size([3072])\n",
      "dbm.encoder.layer.3.output.dense.weight     torch.Size([768, 3072])\n",
      "dbm.encoder.layer.3.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.3.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.3.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.attention.self.query.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.4.attention.self.query.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.attention.self.key.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.4.attention.self.key.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.attention.self.value.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.4.attention.self.value.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.attention.output.dense.weight     torch.Size([768, 768])\n",
      "dbm.encoder.layer.4.attention.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.attention.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.4.attention.output.LayerNorm.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.intermediate.dense.weight     torch.Size([3072, 768])\n",
      "dbm.encoder.layer.4.intermediate.dense.bias     torch.Size([3072])\n",
      "dbm.encoder.layer.4.output.dense.weight     torch.Size([768, 3072])\n",
      "dbm.encoder.layer.4.output.dense.bias     torch.Size([768])\n",
      "dbm.encoder.layer.4.output.LayerNorm.weight     torch.Size([768])\n",
      "dbm.encoder.layer.4.output.LayerNorm.bias     torch.Size([768])\n",
      "head.fc1.weight     torch.Size([1024, 320])\n",
      "head.layer_norm1.weight     torch.Size([1024])\n",
      "head.layer_norm1.bias     torch.Size([1024])\n",
      "head.fc2.weight     torch.Size([1024, 768])\n",
      "head.layer_norm2.weight     torch.Size([1024])\n",
      "head.layer_norm2.bias     torch.Size([1024])\n",
      "head.global_graph.global_graph.attention_decay     torch.Size([1])\n",
      "head.global_graph.global_graph.query.weight     torch.Size([512, 1024])\n",
      "head.global_graph.global_graph.query.bias     torch.Size([512])\n",
      "head.global_graph.global_graph.key.weight     torch.Size([512, 1024])\n",
      "head.global_graph.global_graph.key.bias     torch.Size([512])\n",
      "head.global_graph.global_graph.value.weight     torch.Size([512, 1024])\n",
      "head.global_graph.global_graph.value.bias     torch.Size([512])\n",
      "head.global_graph.global_graph2.attention_decay     torch.Size([1])\n",
      "head.global_graph.global_graph2.query.weight     torch.Size([512, 1024])\n",
      "head.global_graph.global_graph2.query.bias     torch.Size([512])\n",
      "head.global_graph.global_graph2.key.weight     torch.Size([512, 1024])\n",
      "head.global_graph.global_graph2.key.bias     torch.Size([512])\n",
      "head.global_graph.global_graph2.value.weight     torch.Size([512, 1024])\n",
      "head.global_graph.global_graph2.value.bias     torch.Size([512])\n",
      "head.fc3.weight     torch.Size([64, 1024])\n",
      "head.pred.weight     torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "key_to_remove = []\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    print(k, \"   \", v.shape)\n",
    "#     if 'global_graph' in k or 'head.' in k:\n",
    "#         key_to_remove.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e273bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del checkpoint['state_dict']['head.fc3.weight']\n",
    "del checkpoint['state_dict']['head.pred.weight']\n",
    "# for k in key_to_remove:\n",
    "#     del checkpoint['state_dict'][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f2b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = \"../dataset/checkpoints/tmp_1017_no_pred_head.ckpt\"\n",
    "torch.save(\n",
    "{\n",
    "  \"epoch\": checkpoint['epoch'], \n",
    "  \"step\": checkpoint['step'], \n",
    "  \"state_dict\": checkpoint['state_dict'], \n",
    "},\n",
    "path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9fb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
