{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f9faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from preprocessing.protein_chemistry import list_atoms,list_atoms_types,VanDerWaalsRadii,atom_mass,atom_type_to_index,atom_to_index,index_to_type,atom_type_mass\n",
    "from preprocessing.protein_chemistry import residue_dictionary,hetresidue_field\n",
    "\n",
    "from modeling.graph.frames import get_aa_frameCloud, get_atom_frameCloud\n",
    "from preprocessing import sequence_utils\n",
    "\n",
    "\n",
    "\n",
    "def binarize_categorical(matrix, n_classes, out=None):\n",
    "    L = matrix.shape[0]\n",
    "    matrix = matrix.astype(np.int32)\n",
    "    if out is None:\n",
    "        out = np.zeros([L, n_classes], dtype=np.bool_)\n",
    "    subset = (matrix>=0) & (matrix<n_classes)\n",
    "    out[np.arange(L)[subset],matrix[subset]] = 1\n",
    "    return out\n",
    "\n",
    "def readData(file_path):\n",
    "  #处理pdb文本，转为dataframe\n",
    "  with open(file = file_path, mode ='r') as f1:\n",
    "    data = f1.read()\n",
    "    data = data.split('\\n')\n",
    "    del data[-3:]\n",
    "\n",
    "  pdb = []\n",
    "  for i in range(len(data)):\n",
    "    element  = data[i].split()\n",
    "    pdb.append(element)\n",
    "\n",
    "  input = pd.DataFrame(pdb)\n",
    "  #定义存放结果的字典\n",
    "  amino_dict = collections.OrderedDict()\n",
    "  atom_dict= collections.OrderedDict()\n",
    "\n",
    "  for  i in range(len(input)):\n",
    "    #判断是否是H原子\n",
    "    if input.loc[i,11] != 'H':\n",
    "      atom_coord = np.array(input.loc[i,6:8].values,dtype= np.float64)\n",
    "      atom_name = input.loc[i,2]\n",
    "      atom_dict[atom_name] = atom_coord\n",
    "    #判断是否为该pdb文件的最后一个原子\n",
    "    if i == len(input)-1:\n",
    "      amino_name = str(input.loc[i,5]) + '_' + input.loc[i, 3]\n",
    "      amino_dict[amino_name] = atom_dict\n",
    "      atom_dict= collections.OrderedDict()\n",
    "    #非最后一个原子情况下判断是否为该氨基酸最后一个原子\n",
    "    else:\n",
    "      if input.loc[i,5] != input.loc[i+1,5]:\n",
    "        amino_name = str(input.loc[i,5]) + '_' + input.loc[i, 3]\n",
    "        amino_dict[amino_name] = atom_dict\n",
    "        atom_dict= collections.OrderedDict()\n",
    "  return amino_dict\n",
    "\n",
    "def processData(amino_dict):\n",
    "  sequence = \"\"\n",
    "  all_coordinates = []\n",
    "  all_atoms = []\n",
    "  all_atom_types = []\n",
    "  for aa_key, atom_dict in amino_dict.items():\n",
    "    _, aa_name = aa_key.split(\"_\")\n",
    "    sequence += residue_dictionary[aa_name]\n",
    "    # List((3,)) ==> (atoms, 3)\n",
    "    residue_atom_coordinates = np.stack([coord for _, coord in atom_dict.items()], axis=0)\n",
    "    # (atoms,)\n",
    "    residue_atoms = [atom_to_index[atom_name] for atom_name in atom_dict.keys()]\n",
    "    residue_atom_type = [atom_type_to_index[atom_name[0]] for atom_name in atom_dict.keys()]\n",
    "\n",
    "    all_coordinates.append(residue_atom_coordinates)\n",
    "    all_atoms.append(residue_atoms)\n",
    "    all_atom_types.append(residue_atom_type)\n",
    "\n",
    "  return sequence, all_coordinates, all_atoms, all_atom_types\n",
    "  \n",
    "\n",
    "def getdData(file_paths):\n",
    "  batch_sequences = []\n",
    "  batch_all_coordinates = []\n",
    "  batch_all_atoms = []\n",
    "  batch_all_atom_types = []\n",
    "  for file_path in file_paths:\n",
    "    amino_dict = readData(file_path)\n",
    "    sequence, all_coordinates, all_atoms, all_atom_types = processData(amino_dict)\n",
    "\n",
    "    batch_sequences.append(sequence)\n",
    "    batch_all_coordinates.append(all_coordinates)\n",
    "    batch_all_atoms.append(all_atoms)\n",
    "    batch_all_atom_types.append(all_atom_types)\n",
    "\n",
    "  return batch_sequences, batch_all_coordinates, batch_all_atoms, batch_all_atom_types\n",
    "\n",
    "\n",
    "\n",
    "file_paths = [\"../dataset/P44_relaxed_rank_002_alphafold2_ptm_model_2_seed_000.pdb\",]\n",
    "batch_sequences, batch_all_coordinates, batch_all_atoms, batch_all_atom_types = getdData(file_paths)\n",
    "\n",
    "sequence = batch_sequences[0]\n",
    "all_coordinates, all_atoms = batch_all_coordinates[0], batch_all_atoms[0]\n",
    "\n",
    "aa_clouds, aa_triplets, aa_indices = get_aa_frameCloud(all_coordinates, all_atoms)\n",
    "\n",
    "nsequence_features = 20\n",
    "aa_attributes = binarize_categorical(\n",
    "    sequence_utils.seq2num(sequence)[0], 20)\n",
    "\n",
    "\n",
    "atom_clouds, atom_triplets, atom_attributes, atom_indices = get_atom_frameCloud(sequence, all_coordinates, all_atoms)\n",
    "\n",
    "\n",
    "########################################\n",
    "from modeling.graph.neighborhoods import FrameBuilder\n",
    "\n",
    "tensor_aa_clouds = torch.Tensor(aa_clouds).unsqueeze(0)\n",
    "tensor_aa_triplets = torch.Tensor(aa_triplets).unsqueeze(0)\n",
    "tensor_aa_triplets = tensor_aa_triplets.long()\n",
    "\n",
    "tensor_aa_indices = torch.Tensor(aa_indices).unsqueeze(0)\n",
    "\n",
    "config = None\n",
    "frame_builder = FrameBuilder(config)\n",
    "\n",
    "inputs = [tensor_aa_clouds, tensor_aa_triplets]\n",
    "frames = frame_builder(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef2a580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acacbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 518, 4, 3]) torch.Size([1, 518, 1]) torch.Size([1, 518, 20])\n",
      "torch.Size([1, 518, 16, 3])\n",
      "torch.Size([1, 518, 16, 1])\n",
      "torch.Size([1, 518, 16, 1])\n",
      "torch.Size([1, 518, 16, 1])\n",
      "torch.Size([1, 518, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "from modeling.graph.neighborhoods import LocalNeighborhood\n",
    "\n",
    "coordinates=['euclidian', 'index_distance', 'ZdotZ', 'ZdotDelta']\n",
    "\n",
    "local_neighborhood = LocalNeighborhood(\n",
    "    config, Kmax=16, coordinates=coordinates, self_neighborhood=True, index_distance_max=8, nrotations=1)\n",
    "\n",
    "tensor_aa_attributes = torch.Tensor(aa_attributes)\n",
    "tensor_aa_attributes = tensor_aa_attributes.unsqueeze(0)\n",
    "\n",
    "print( frames.shape, tensor_aa_indices.shape, tensor_aa_attributes.shape )\n",
    "\n",
    "input2localneighborhood = [frames, tensor_aa_indices, tensor_aa_attributes]\n",
    "output = local_neighborhood(input2localneighborhood)\n",
    "\n",
    "neighbor_coordinates, neighbors_attributes = output[0][0], output[1]\n",
    "\n",
    "neighbor_coordinates.shape, neighbors_attributes.shape\n",
    "\n",
    "for out in output[0]:\n",
    "    print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0894c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518 518\n",
      "(1037, 3) torch.Size([1, 1037, 3])\n",
      "(518, 1) torch.Size([1, 518, 1])\n",
      "['frame', 'index'] ['frame', 'index']\n",
      "['euclidian', 'index_distance', 'ZdotZ', 'ZdotDelta'] ['frame', 'index'] 1\n"
     ]
    }
   ],
   "source": [
    "print(len(all_coordinates), len(all_atoms))\n",
    "print(aa_clouds.shape, tensor_aa_clouds.shape)\n",
    "print(aa_indices.shape, tensor_aa_indices.shape)\n",
    "print( local_neighborhood.first_format, local_neighborhood.second_format )\n",
    "print( local_neighborhood.coordinates, local_neighborhood.first_format, local_neighborhood.first_format.index('index') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "from modeling.lib import MLP, GlobalGraph, LayerNorm, CrossAttention, GlobalGraphRes, TimeDistributed\n",
    "\n",
    "\n",
    "class GaussianKernel(nn.Module):\n",
    "  def __init__(self, d, N, initial_values, covariance_type='diag', eps=1e-1, **kwargs):\n",
    "    super(GaussianKernel, self).__init__(**kwargs)\n",
    "    self.support_masking = True\n",
    "    self.eps = eps\n",
    "    self.N = N # 32 for example\n",
    "    self.initial_values = initial_values\n",
    "    self.covariance_type = covariance_type\n",
    "    assert self.covariance_type in ['diag', 'full']\n",
    "\n",
    "    ## build\n",
    "    self.d = d\n",
    "    self.center_shape = torch.Size([self.d, self.N])\n",
    "    self.kernel_centers = torch.nn.Parameter(data=torch.Tensor(self.center_shape), requires_grad=True) # (d,N)\n",
    "    self.kernel_widths = None\n",
    "    self.sqrt_precision = None\n",
    "    \n",
    "    if self.covariance_type == 'diag':\n",
    "      self.width_shape = torch.Size([self.d, self.N])\n",
    "      self.kernel_widths = torch.nn.Parameter(data=torch.Tensor(self.width_shape), requires_grad=True) # (d,N)\n",
    "      # self.kernel_widths.fill_(1.0)\n",
    "    elif self.covariance_type == 'full':\n",
    "      self.sqrt_precision_shape = torch.Size([self.d, self.d, self.N])\n",
    "      self.sqrt_precision = torch.nn.Parameter(data=torch.Tensor(self.sqrt_precision_shape), requires_grad=True) # (d, d,N)\n",
    "      # self.sqrt_precision.fill_(1.0)\n",
    "    \n",
    "    nn.init.kaiming_normal_(self.kernel_centers, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "    if self.kernel_widths is not None:\n",
    "      nn.init.kaiming_normal_(self.kernel_widths, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "    if self.sqrt_precision is not None:\n",
    "      nn.init.kaiming_normal_(self.sqrt_precision, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "    \n",
    "    \n",
    "        \n",
    "  def forward(self, x):\n",
    "    nbatch_dim   = len(x.shape) - 1\n",
    "    input_size   = torch.Size([1 for _ in range(nbatch_dim)])\n",
    "    centers_size = input_size + self.center_shape # [1,1,1,5,N]\n",
    "\n",
    "    if self.covariance_type == 'diag':\n",
    "      base_size = input_size + self.width_shape # [1,1,1,5,N]\n",
    "      # (bs,seq,32,5,1) - (1,1,1,d=5,N) = (bs,seq,32,5,N)\n",
    "      base = (kernel_widths + self.eps).reshape(base_size)\n",
    "      x = ( x.unsqueeze(dim=-1) - self.kernel_centers.reshape(centers_size) ) / base\n",
    "      activity = torch.exp( -0.5 * torch.sum(x**2, dim=-2) )\n",
    "    elif self.covariance_type == 'full':\n",
    "      # (bs,seq,32,5,1) - (1,1,1,d=5,N) = (bs,seq,32,5,N)\n",
    "      intermediate  = x.unsqueeze(dim=-1) - self.kernel_centers.reshape(centers_size)\n",
    "      # (bs,seq,32,1,5,N) * (1,5,5,N) = (bs,seq,32,5,5,N) = (bs,seq,32,5,N)\n",
    "      intermediate2 = torch.sum(intermediate.unsqueeze(dim=-3) * self.sqrt_precision.unsqueeze(dim=0), dim=-2)\n",
    "      activity = torch.exp(-0.5 * torch.sum(intermediate2**2, dim=-2)) # (bs,seq,32,N)\n",
    "    else:\n",
    "      activity = None\n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0f49403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidian_coords shape=torch.Size([1, 518, 16, 3])\n",
      "embedded_local_coordinates shape=torch.Size([1, 518, 16, 32])\n",
      "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64), tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))\n"
     ]
    }
   ],
   "source": [
    "# from modeling.graph.embeddings import GaussianKernel\n",
    "\n",
    "Ngaussians = 32\n",
    "# initial_values = (torch.zeros(3,Ngaussians), torch.zeros(3,3,Ngaussians))\n",
    "initial_values = (torch.rand(3,Ngaussians), torch.rand(3,3,Ngaussians))\n",
    "covariance_type = \"full\"\n",
    "\n",
    "guassian_kernel = GaussianKernel(d=3, N=Ngaussians, \n",
    "                              initial_values=None, \n",
    "                              covariance_type=covariance_type)\n",
    "euclidian_coords = output[0][0]\n",
    "print(\"euclidian_coords shape={}\".format( euclidian_coords.shape ))\n",
    "embedded_local_coordinates = guassian_kernel(euclidian_coords)\n",
    "print(\"embedded_local_coordinates shape={}\".format( embedded_local_coordinates.shape ))\n",
    "print( torch.where( torch.isnan(embedded_local_coordinates) == True ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe63a3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 518, 16, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_coords = output[0]\n",
    "torch.cat(neighbor_coords, dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38650f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingOuterProduct(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super(EmbeddingOuterProduct, self).__init__()\n",
    "    self.config = config # not used any more\n",
    "\n",
    "    self.sum_axis = 2\n",
    "    self.use_bias = False\n",
    "    self.kernel12 = torch.nn.Parameter(data=torch.Tensor(32, 20, 128), requires_grad=True)\n",
    "    self.kernel1 = torch.nn.Parameter(data=torch.Tensor(32, 128), requires_grad=True)\n",
    "    self.bias = torch.nn.Parameter(data=torch.Tensor(128), requires_grad=True)\n",
    "    # init\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    first_input = inputs[0] # [bs, seq, k, feat]\n",
    "    second_input = inputs[1] # [bs, seq, k, feat]\n",
    "\n",
    "    if self.sum_axis is not None:\n",
    "      temp = torch.unsqueeze(first_input, dim=-1) \\\n",
    "            * torch.unsqueeze(second_input, dim=-2)\n",
    "      outer_product = torch.sum(temp, dim=self.sum_axis)\n",
    "\n",
    "    activity = torch.tensordot(outer_product, self.kernel12, dims=([-2, -1], [0, 1]))\n",
    "\n",
    "    activity += torch.tensordot(first_input.sum(dim=self.sum_axis), self.kernel1, ([-1],[0]))\n",
    "    if self.use_bias:\n",
    "      activity += self.bias.reshape(1, 1, -1)\n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "687a2388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 518, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = EmbeddingOuterProduct(config=None)\n",
    "out = op( [embedded_local_coordinates, neighbors_attributes] )\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89b67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 518, 16, 32]) torch.Size([1, 518, 16, 20])\n"
     ]
    }
   ],
   "source": [
    "print(embedded_local_coordinates.shape, neighbors_attributes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "491df306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04a5a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 518, 4, 3]), torch.Size([1, 518, 1]), torch.Size([1, 518, 20]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape, tensor_aa_indices.shape, tensor_aa_attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e805259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frame', 'index']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_neighborhood.first_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566f1a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00567709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.graph.layers import Linear\n",
    "\n",
    "hidden_dim = 64\n",
    "norm = \"GN\"\n",
    "ng = 1\n",
    "l1 = Linear(20, hidden_dim, norm=norm, ng=ng, act=False)\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78385ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = l1(tensor_aa_attributes.reshape(-1, 20))\n",
    "x = x.reshape(1, -1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2localneighborhood = [frames, x]\n",
    "output = local_neighborhood(input2localneighborhood)\n",
    "\n",
    "neighbor_coordinates, neighbors_attributes = output[0][0], output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_attributes[0,0,:,0],neighbors_attributes[0,0,:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ad6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2= torch.sum(neighbors_attributes, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(neighbors_attributes[0,0,:,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb99124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f60187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapNet(nn.Module):\n",
    "\n",
    "  def __init__(self, hidden_dim, ):\n",
    "    super(MapNet, self).__init__()\n",
    "    # self.config = config\n",
    "    # hidden_dim = config[\"hidden_dim\"] # 128\n",
    "    norm = \"GN\"\n",
    "    ng = 1\n",
    "\n",
    "    self.input = nn.Sequential(\n",
    "      nn.Linear(20, hidden_dim),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Linear(hidden_dim, hidden_dim, norm=norm, ng=ng, act=False),\n",
    "    )\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    coordinates=['euclidian',]\n",
    "    self.fuse = []\n",
    "    self.edge = []\n",
    "    self.norm = []\n",
    "    self.ctr2 = []\n",
    "    # self.local_neighborhood = []\n",
    "    self.local_neighborhood = LocalNeighborhood(\n",
    "      config, Kmax=16, coordinates=coordinates, \n",
    "      self_neighborhood=True, index_distance_max=8, nrotations=1)\n",
    "      \n",
    "    for i in range(4):\n",
    "      self.fuse.append(\n",
    "        nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "      )\n",
    "      self.edge.append(\n",
    "        nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "      )\n",
    "      self.norm.append(nn.GroupNorm(gcd(ng, hidden_dim), hidden_dim))\n",
    "      self.ctr2.append(Linear(hidden_dim, hidden_dim, norm=norm, ng=ng, act=False))\n",
    "    self.fuse = nn.ModuleList(self.fuse)\n",
    "    self.edge = nn.ModuleList(self.edge)\n",
    "    self.norm = nn.ModuleList(self.norm)\n",
    "    self.ctr2 = nn.ModuleList(self.ctr2)\n",
    "\n",
    "\n",
    "  def forward(self, x, frames, ):\n",
    "    # input (bs, seq, 20)\n",
    "    bs_dim, seq_dim, input_dim = x.shape\n",
    "    x = x.reshape(bs_dim * seq_dim, -1)\n",
    "    x = self.input(x) # (bs*seq, 20) => (bs*seq, hidden)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    # x = x.reshape(bs_dim, seq_dim, -1)\n",
    "\n",
    "    res = x # (bs*seq, h)\n",
    "    for i in range(4):\n",
    "      x_node = self.fuse[i](x)\n",
    "      x_edge = self.edge[i](x)\n",
    "\n",
    "      x_edge = x_edge.reshape(bs_dim, seq_dim, -1)\n",
    "      input2localneighborhood = [frames, x_edge] # (bs, seq, 1)\n",
    "      output = self.local_neighborhood(input2localneighborhood)\n",
    "      # (bs, seq, 16, 3), (bs, seq, 16, h)\n",
    "      neighbor_coordinates, neighbors_attributes = output[0][0], output[1]\n",
    "      tmp = torch.sum(neighbors_attributes, -2) # (bs, seq, h)\n",
    "      tmp = tmp.reshape(bs_dim * seq_dim, -1)\n",
    "\n",
    "      x = x_node + tmp\n",
    "\n",
    "      x = self.norm[i](x)\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.ctr2[i](x)\n",
    "      x += res\n",
    "      x = self.relu(x)\n",
    "      res = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "net = MapNet(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09d0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(tensor_aa_attributes, frames)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb905999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(torch.Size([2,3] + [1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3b11889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 32, 5, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,10,32,5)\n",
    "centers = torch.rand(5,3)\n",
    "x.shape[:-1] + torch.Size([5,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "703a6f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 6, 5, 5, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,10,6,1,5,32)\n",
    "y = torch.rand(1,5,5,32)\n",
    "(x*y).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
