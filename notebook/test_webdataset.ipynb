{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d8d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import webdataset as wds\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle, zlib\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import random\n",
    "import zlib\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Process\n",
    "from random import choice\n",
    "import argparse\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessing.protein_chemistry import list_atoms,list_atoms_types,VanDerWaalsRadii,atom_mass,atom_type_to_index,atom_to_index,index_to_type,atom_type_mass\n",
    "from preprocessing.protein_chemistry import residue_dictionary,hetresidue_field\n",
    "from preprocessing import sequence_utils\n",
    "\n",
    "from modeling.graph.frames import get_aa_frameCloud, get_atom_frameCloud\n",
    "from modeling.graph.neighborhoods import FrameBuilder, LocalNeighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61016667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(inputs):\n",
    "    x, y, z = [], [], []\n",
    "#     print(type(inputs), len(inputs))\n",
    "    for it in inputs:\n",
    "        x.append( pickle.loads(zlib.decompress( it[\"protein\"] )) )\n",
    "        y.append( pickle.loads(zlib.decompress( it[\"dna\"] )) )\n",
    "        z.append( pickle.loads(zlib.decompress( it[\"label\"] )) )\n",
    "        \n",
    "    return x, y, z\n",
    "\n",
    "url = \"/home/paul/Data/datasets/dna_intensity_dataset/example/dna-1k-{000001..000002}.tar\"\n",
    "dataset = wds.WebDataset(url)\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=16, collate_fn=convert)\n",
    "\n",
    "\n",
    "for item in dataloader:\n",
    "    tensor_feats, tensor_frames, labels = item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1091fe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 12, 2).squeeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfde520a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a5028ea8bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# print(len(item[\"label\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dna\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "for item in dataloader:\n",
    "    print(item.keys())\n",
    "    # print(len(item[\"label\"]))\n",
    "    for l, d in zip(item[\"label\"], item[\"dna\"]):\n",
    "        l = pickle.loads(zlib.decompress( l ))\n",
    "        d = pickle.loads(zlib.decompress( d ))\n",
    "        print(x, d)\n",
    "    # pickle.loads()\n",
    "    # x = pickle.loads(zlib.decompress(item[\"protein\"]))\n",
    "    # print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941eba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db054989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146274be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b29f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a9be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f15d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readPdbFile(file_path):\n",
    "  r\"\"\"\n",
    "  read a pdb file\n",
    "  \"\"\"\n",
    "  if not os.path.exists(file_path):\n",
    "    print(\"error: following file not exists, {}\".format(file_path))\n",
    "    return\n",
    "  #处理pdb文本，转为dataframe\n",
    "  with open(file = file_path, mode ='r') as f1:\n",
    "    data = f1.read()\n",
    "    data = data.split('\\n')\n",
    "    del data[-3:]\n",
    "\n",
    "  pdb = []\n",
    "  for i in range(len(data)):\n",
    "    element  = data[i].split()\n",
    "    pdb.append(element)\n",
    "\n",
    "  input = pd.DataFrame(pdb)\n",
    "  #定义存放结果的字典\n",
    "  amino_dict = collections.OrderedDict()\n",
    "  atom_dict= collections.OrderedDict()\n",
    "\n",
    "  for i in range(len(input)):\n",
    "    #判断是否是H原子\n",
    "    if input.loc[i,11] != 'H':\n",
    "      atom_coord = np.array(input.loc[i,6:8].values,dtype= np.float64)\n",
    "      atom_name = input.loc[i,2]\n",
    "      atom_dict[atom_name] = atom_coord\n",
    "    #判断是否为该pdb文件的最后一个原子\n",
    "    if i == len(input)-1:\n",
    "      amino_name = str(input.loc[i,5]) + '_' + input.loc[i, 3]\n",
    "      amino_dict[amino_name] = atom_dict\n",
    "      atom_dict= collections.OrderedDict()\n",
    "    #非最后一个原子情况下判断是否为该氨基酸最后一个原子\n",
    "    else:\n",
    "      if input.loc[i,5] != input.loc[i+1,5]:\n",
    "        amino_name = str(input.loc[i,5]) + '_' + input.loc[i, 3]\n",
    "        amino_dict[amino_name] = atom_dict\n",
    "        atom_dict= collections.OrderedDict()\n",
    "  return amino_dict\n",
    "\n",
    "def processDataPdbFormat(amino_dict):\n",
    "  sequence = \"\"\n",
    "  all_coordinates = []\n",
    "  all_atoms = []\n",
    "  all_atom_types = []\n",
    "  for aa_key, atom_dict in amino_dict.items():\n",
    "    _, aa_name = aa_key.split(\"_\")\n",
    "    sequence += residue_dictionary[aa_name]\n",
    "    # List((3,)) ==> (atoms, 3)\n",
    "    residue_atom_coordinates = np.stack([coord for _, coord in atom_dict.items()], axis=0)\n",
    "    # (atoms,)\n",
    "    residue_atoms = [atom_to_index[atom_name] for atom_name in atom_dict.keys()]\n",
    "    residue_atom_type = [atom_type_to_index[atom_name[0]] for atom_name in atom_dict.keys()]\n",
    "\n",
    "    all_coordinates.append(residue_atom_coordinates)\n",
    "    all_atoms.append(residue_atoms)\n",
    "    all_atom_types.append(residue_atom_type)\n",
    "\n",
    "  return sequence, all_coordinates, all_atoms, all_atom_types\n",
    "\n",
    "def getDataPdbFormat(file_paths):\n",
    "  batch_sequences = []\n",
    "  batch_all_coordinates = []\n",
    "  batch_all_atoms = []\n",
    "  batch_all_atom_types = []\n",
    "  for file_path in file_paths:\n",
    "    amino_dict = readPdbFile(file_path)\n",
    "    sequence, all_coordinates, all_atoms, all_atom_types = processDataPdbFormat(amino_dict)\n",
    "\n",
    "    batch_sequences.append(sequence)\n",
    "    batch_all_coordinates.append(all_coordinates)\n",
    "    batch_all_atoms.append(all_atoms)\n",
    "    batch_all_atom_types.append(all_atom_types)\n",
    "\n",
    "  return batch_sequences, batch_all_coordinates, batch_all_atoms, batch_all_atom_types\n",
    "\n",
    "def binarize_categorical(matrix, n_classes, out=None):\n",
    "  L = matrix.shape[0]\n",
    "  matrix = matrix.astype(np.int32)\n",
    "  if out is None:\n",
    "    out = np.zeros([L, n_classes], dtype=np.bool_)\n",
    "  subset = (matrix>=0) & (matrix<n_classes)\n",
    "  out[np.arange(L)[subset],matrix[subset]] = 1\n",
    "  return out\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
